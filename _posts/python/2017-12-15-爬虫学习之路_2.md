---
layout: post
title: 爬虫学习之路 - 常用库 
date: 2017-12-15
excerpt: "爬虫学习之路 - 常用库"
categories: Python
tags: [Python]
comments: true
---


# 基础库

了解了Python语法，搭建完成了环境，我们也感受了几个小例子。

是时候来看看一些基础库：urllib,urlllib2,通过 openurl('url') 发送请求，接受返回数据。

网站的验证方法复杂多样[防盗链，cookie，登录验证，各种密钥，动态token]，这正是数据爬虫的难度所在，也是爬虫工作者存在的价值。

通过各种验证顺利完成请求，后面python正则分分钟，格式化出你想要的数据。


# 进阶库

- Requests库：主要是简化请求工作
- Beautiful Soup：取代枯燥易错的正则表达式，简化数据匹配，快速清洗
- Xpath语法lxml：主要了解文档结构，知己知彼，好下手
- PhantomJS：处理网页中的动态js请求，模拟浏览器完成js的渲染，等到异步情节，保证文档结构数据的完整性，所见即所得（这个我们后面也会用到）
- Selenium：模拟浏览事件，支持多步连续请求，减少人工手动触发［登录表单填写，触发表单发送，调整登录成功页等］
- pyQuery：顾名思义，用python语言复制一版jquery
- pandas: 表格处理库
- mysql.connector： python操作mysql

