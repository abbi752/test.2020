---
layout: post
title: 大数据学习-Hadoop安装运行
date: 2018-6-25
excerpt: "大数据学习-Hadoop安装运行"
categories: 大数据
tags: [大数据]
---

* content
{:toc}




# 简介

安装运行笔记，记录于2018/6/25

# 安装

安装版本hadoop 2.8.3

1. 先确认[winutils](https://github.com/steveloughran/winutils)上支持的版本（Windows安装需要这个工具），选择版本下载
2. 下载hadoop：[http://hadoop.apache.org ](http://hadoop.apache.org)
3. 将winutils中的对应版本的bin覆盖替换到hadoop的bin（为了能在windows上使用）

# 配置环境

1. 添加Hadoop环境变量

	- 添加HADOOP_HOME环境变量，指向Hadoop路径，例如D:\hadoop2.8.3
	- Path中加入%HADOOP_HOME%\bin

2. 配置Java环境变量：

	jdk路径配置在文件hadoop\etc\hadoop\hadoop-env.cmd中，默认是%JAVA_HOME%。如果之前有配置过环境变量则不用做什么
	
	你也可以直接写例如：（路径最好没有空格）

		set JAVA_HOME=D:\RequiredTools\Java\jdk8u45 

	这里要注意，hadoop不识别为有空格的路径，如果路径有空格可以加双引号，例如："C:\Program Files"\Java\jdk-10.0.1

		set JAVA_HOME="C:\Program Files"\Java\jdk-10.0.1


配置完成后，cmd执行：

	hadoop version

可以看到hadoop版本提示

	>hadoop version
	'C:\Program' 不是内部或外部命令，也不是可运行的程序 （这错误提示句没关系，不影响后面的执行）
	或批处理文件。
	Hadoop 2.8.3
	Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r b3fe56402d908019d99af1f1f4fc65cb1d1436a2
	Compiled by jdu on 2017-12-05T03:43Z
	Compiled with protoc 2.5.0
	From source with checksum 9ff4856d824e983fa510d3f843e3f19d
	This command was run using /D:/hadoop2.8.3/share/hadoop/common/hadoop-common-2.8.3.jar

# 实践一： hadoop计算圆周率 （本地独立模式）

Hadoop运行模式：本地独立模式

- cmd cd到hadoop根目录，执行

		hadoop jar share\hadoop\mapreduce\hadoop-mapreduce-examples-2.8.3.jar pi 4 1000 > pi_demo.txt

	后面2个数字参数的含义： 

     第1个4指的是要运行4次map任务 

     第2个数字指的是每个map任务，要投掷多少次

- pi_demo.txt的结果如下：

		Number of Maps  = 4
		Samples per Map = 1000
		Wrote input for Map #0
		Wrote input for Map #1
		Wrote input for Map #2
		Wrote input for Map #3
		Starting Job
		Job Finished in 4.783 seconds
		Estimated value of Pi is 3.14000000000000000000

- cmd中可以看到很多输出信息

	
	![](https://i.imgur.com/AzAILAS.png)

	![](https://i.imgur.com/M4c1T8E.png)


注意事项：本地独立模式仅需要配置hadoop-env.cmd中的Java环境即可（core-site.xml，hdfs-site.xml等都不要配置，否则可能运行失败）


# 实践二： wordcount 统计词频 （伪分布模式）

## 1. 配置伪分布模式

1. 配置etc\hadoop\core-site.xml

		  <configuration>
		    <property>  
		　　　　<name>fs.default.name</name>  
		　　　　<value>hdfs://localhost:9000</value>  
		　　 </property>     
		  </configuration>

	fs.default.name保存了NameNode的位置，HDFS和MapReduce组件都需要它

2. 配置etc\hadoop\hdfs-site.xml

		<configuration>
			<property>  
			　　<name>dfs.replication</name>  
			　　<value>1</value>  
			</property>
			<property>
			   <name>dfs.namenode.name.dir</name>
			   <value>file:/hadoop/data/dfs/namenode</value>
			</property>
			<property>
			    <name>dfs.datanode.data.dir</name>
			    <value>file:/hadoop/data/dfs/datanode</value>
			</property> 
		</configuration>
	
	- dfs.replication指定了每个HDFS数据块的复制次数。HDFS确保每个数据块被复制到多台不同主机（通常是3台），以此方式处理故障。

		这里测试只有一台主机和一个伪分布式模式的DataNode，将此值修改为1
	
3. etc\hadoop\mapred-site.xml

	mapred-site.xml如果没有可以复制mapred-site.xml.template, 然后去掉template

		<configuration>
		    <property>
		       <name>mapreduce.framework.name</name>
		       <value>yarn</value>
		    </property>
		</configuration>


4. 配置etc\hadoop\yarn-site.xml 

		<configuration>
		    <property>
		       <name>yarn.nodemanager.aux-services</name>
		       <value>mapreduce_shuffle</value>
		    </property>
		    <property>
		       <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
		       <value>org.apache.hadoop.mapred.ShuffleHandler</value>
		    </property>
		</configuration>

## 2. 格式化NameNode

	hadoop namenode -format

会在D:\hadoop2.8.3同级目录下生产D:\hadoop\data 目录

## 3. 启动hadoop

1. cmd 先cd到sbin， 运行

		start-dfs.cmd   //先启动dfs  
		start-yarn.cmd  //再启动yarn  
		//或者
		//start-all.cmd //相当于以上的两条命令

	执行完成后可以看到下面四个窗口启动：hadoop namenode, hadoop datanode, yarn resourecemanager, yarn nodemanager

2. jps查看进程

	jps

	红色是刚才命令启动的进程

	![](https://i.imgur.com/gaXdxSy.png)

3. 网页查看集群和hadoop情况

	hadoop：http://localhost:50070 

	![](https://i.imgur.com/Lsfp44E.png)

	集群：http://localhost:8088/cluster

	![](https://i.imgur.com/hRCEEVz.png)

4. wordcount

	- 创建测试文件test.txt，内容

			This is a test

	- cmd 先hadoop2.8.3

			上传文件到hdfs
			hadoop dfs -put ../test.txt /  

			执行程序wordcount，统计词频
			hadoop jar share\hadoop\mapreduce\hadoop-mapreduce-examples-2.8.3.jar wordcount /testdata /testresult

			其中testdata是输入; testresult是输出

	因为jobhistroy等在Windows上运行一直出现问题。待之后用Linux测试后再来更新结果。

# 遇到的问题

Java.lang.Exception:Unknown container问题

[开启Hadoop/Yarn的日志监控功能,解决web端查看日志时的Java.lang.Exception:Unknown container问题](https://blog.csdn.net/lisongjia123/article/details/78639058)

[hadoop配置启动historyserver](https://blog.csdn.net/tszxlzc/article/details/74838674)

# Reference

[windows下安装并启动hadoop2.7.2](https://www.cnblogs.com/wuxun1997/p/6847950.html)

[hadoop,windows下安装](https://blog.csdn.net/xrui_java7/article/details/70231221)

[Windows环境下 Hadoop Error: JAVA_HOME is incorrectly set. 问题](https://blog.csdn.net/wen3011/article/details/54907731)

[hadoop例子程序：求圆周率和wordcount](https://www.cnblogs.com/xiaoxiao5ya/p/da686507959026b16d479ca07876bc04.html)

[Hadoop配置文件配置项定义说明](https://blog.csdn.net/xuechongyang/article/details/8691518)

